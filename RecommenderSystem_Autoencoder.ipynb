{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RecommenderSystem_Autoencoder.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GeniGaus/DeepLearningA-Z/blob/master/RecommenderSystem_Autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "RWGVykGtCkC_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Autoencoder\n",
        "----\n"
      ]
    },
    {
      "metadata": {
        "id": "M_BKOUxKCaMW",
        "colab_type": "code",
        "outputId": "77c50339-9599-46ee-b47e-646dc3ae02f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "# Install a Drive FUSE wrapper.\n",
        "# https://github.com/astrada/google-drive-ocamlfuse\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package libfuse2:amd64.\n",
            "(Reading database ... 22278 files and directories currently installed.)\n",
            "Preparing to unpack .../libfuse2_2.9.7-1ubuntu1_amd64.deb ...\n",
            "Unpacking libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
            "Selecting previously unselected package fuse.\n",
            "Preparing to unpack .../fuse_2.9.7-1ubuntu1_amd64.deb ...\n",
            "Unpacking fuse (2.9.7-1ubuntu1) ...\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.0-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.0-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Setting up fuse (2.9.7-1ubuntu1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.0-0ubuntu1~ubuntu18.04.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DmllhAp4Crye",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Generate auth tokens for Colab\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WwzLgj49Cu8f",
        "colab_type": "code",
        "outputId": "22f304a9-e375-4348-dc3b-a24279553ab3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "# Generate creds for the Drive FUSE library.\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MGYXL8nsCxQ3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create a directory and mount Google Drive using that directory.\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_H14vUZ6C1zq",
        "colab_type": "code",
        "outputId": "ba4c3e98-0bb7-42b4-c706-a2b7ff1e7eac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "## Install Pytorch\n",
        "\n",
        "# http://pytorch.org/\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1073750016 bytes == 0x5b424000 @  0x7f0ee33f92a4 0x594e17 0x626104 0x51190a 0x4f5277 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x4f3338 0x510fb0 0x5119bd 0x4f6070\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "M8gyD1oVDAc9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('drive/BoltzmannMachine')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LtQWixlCDMWj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###  Building autoencoder model using Pytorch\n",
        "----\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "xfh1ofthQTOk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Data preprocessing\n"
      ]
    },
    {
      "metadata": {
        "id": "dQ2Dz_RhDVKf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ScR8Wdr6DZe1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# importing dataset\n",
        "movies = pd.read_csv('ml-1m/movies.dat', sep='::', engine='python', encoding='latin-1')\n",
        "users = pd.read_csv('ml-1m/users.dat', sep='::', engine='python', encoding='latin-1')\n",
        "ratings = pd.read_csv('ml-1m/ratings.dat', sep='::', engine='python', encoding='latin-1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ykEh-z7gDevT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# forming training and test set\n",
        "training_set = pd.read_csv('ml-100k/u1.base', delimiter='\\t')\n",
        "training_set = np.array(training_set, dtype='int')\n",
        "test_set = pd.read_csv('ml-100k/u1.test', delimiter='\\t')\n",
        "test_set = np.array(test_set, dtype='int')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wdZNC1dADke6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# total no. of users and movies\n",
        "nb_users = int(max(max(training_set[:, 0]), max(test_set[:, 0])))\n",
        "nb_movies = int(max(max(training_set[:, 1]), max(test_set[:, 1])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wqlighnKDoFB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create training and test matrices where each line is user, each column is movie and each cell contains the rating which that user gave for the movie.\n",
        "# If the user gave no rating, then 0 is placed in that cell.\n",
        "# This will create the input structure which the Boltzmann machine expects,i.e. observations in lines and features in columns.\n",
        "\n",
        "'''rating_matrix = np.zeros((nb_users, nb_movies), dtype='int')\n",
        "full_set = np.concatenate((training_set, test_set), axis=0)\n",
        "for i in range(len(full_set)):\n",
        "  rating_matrix[full_set[i][0]][full_set[i][1]] = full_set[i][2]\n",
        "'''\n",
        "\n",
        "def convert(data):\n",
        "  converted_data = []\n",
        "  for user_id in range(nb_users + 1):\n",
        "    movies_ids = data[:, 1][data[:, 0] == user_id]\n",
        "    ratings_data = data[:, 2][data[:, 0] == user_id]\n",
        "    ratings = np.zeros((nb_movies))\n",
        "    ratings[movies_ids - 1] = ratings_data\n",
        "    converted_data.append(ratings)\n",
        "  \n",
        "  return converted_data\n",
        " \n",
        "training_set = convert(training_set)\n",
        "test_set = convert(test_set)\n",
        "\n",
        "training_set = torch.FloatTensor(training_set)\n",
        "test_set = torch.FloatTensor(test_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qxZLQAP3QeSP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model Creation"
      ]
    },
    {
      "metadata": {
        "id": "-KOb9HsEQhSg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SAE(nn.Module):\n",
        "  \n",
        "  def __init__(self,):\n",
        "    super(SAE, self).__init__()\n",
        "    self.fc1 = nn.Linear(nb_movies, 128)\n",
        "    self.fc2 = nn.Linear(128, 64)\n",
        "    self.fc3 = nn.Linear(64, 32)\n",
        "    self.fc4 = nn.Linear(32, 64)\n",
        "    self.fc5 = nn.Linear(64, 128)\n",
        "    self.fc6 = nn.Linear(128, nb_movies)\n",
        "    self.activation = nn.Sigmoid()\n",
        " \n",
        "  def forward(self, x):\n",
        "    x = self.activation(self.fc1(x))\n",
        "    x = self.activation(self.fc2(x))\n",
        "    x = self.activation(self.fc3(x))\n",
        "    x = self.activation(self.fc4(x))\n",
        "    x = self.activation(self.fc5(x))\n",
        "    x = self.fc6(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nY3jklQfWPGm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sae = SAE()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.RMSprop(sae.parameters(), lr = 0.01, weight_decay = 0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0vfJzu7bEAIh",
        "colab_type": "code",
        "outputId": "1114b71f-6b46-435c-d328-f5cb6e4834a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3471
        }
      },
      "cell_type": "code",
      "source": [
        "# training the model\n",
        "\n",
        "nb_epochs = 200\n",
        "for epoch in range(1, nb_epochs + 1):\n",
        "  training_loss = 0.\n",
        "  s = 0.\n",
        "  for id_user in range(nb_users):\n",
        "    input = Variable(training_set[id_user]).unsqueeze(0)\n",
        "    target = input.clone()\n",
        "    if torch.sum(target.data > 0) > 0:\n",
        "      output = sae(input)\n",
        "      output[target == 0] = 0\n",
        "      target.require_grad = False\n",
        "      loss = criterion(output, target)\n",
        "      mean_corrector = nb_movies / float(torch.sum(target.data > 0) + 1e-10)\n",
        "      loss.backward()\n",
        "      training_loss += np.sqrt(loss.data[0] * mean_corrector)\n",
        "      s += 1.\n",
        "      optimizer.step()\n",
        "  print('epoch: '+str(epoch)+' loss:'+str(training_loss/s))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
            "  app.launch_new_instance()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 1 loss:tensor(1.4286)\n",
            "epoch: 2 loss:tensor(1.2000)\n",
            "epoch: 3 loss:tensor(1.1649)\n",
            "epoch: 4 loss:tensor(1.1187)\n",
            "epoch: 5 loss:tensor(1.0916)\n",
            "epoch: 6 loss:tensor(1.0831)\n",
            "epoch: 7 loss:tensor(1.0777)\n",
            "epoch: 8 loss:tensor(1.0735)\n",
            "epoch: 9 loss:tensor(1.0710)\n",
            "epoch: 10 loss:tensor(1.0675)\n",
            "epoch: 11 loss:tensor(1.0655)\n",
            "epoch: 12 loss:tensor(1.0647)\n",
            "epoch: 13 loss:tensor(1.0616)\n",
            "epoch: 14 loss:tensor(1.0591)\n",
            "epoch: 15 loss:tensor(1.0581)\n",
            "epoch: 16 loss:tensor(1.0562)\n",
            "epoch: 17 loss:tensor(1.0537)\n",
            "epoch: 18 loss:tensor(1.0527)\n",
            "epoch: 19 loss:tensor(1.0494)\n",
            "epoch: 20 loss:tensor(1.0487)\n",
            "epoch: 21 loss:tensor(1.0470)\n",
            "epoch: 22 loss:tensor(1.0451)\n",
            "epoch: 23 loss:tensor(1.0444)\n",
            "epoch: 24 loss:tensor(1.0430)\n",
            "epoch: 25 loss:tensor(1.0417)\n",
            "epoch: 26 loss:tensor(1.0419)\n",
            "epoch: 27 loss:tensor(1.0417)\n",
            "epoch: 28 loss:tensor(1.0392)\n",
            "epoch: 29 loss:tensor(1.0391)\n",
            "epoch: 30 loss:tensor(1.0385)\n",
            "epoch: 31 loss:tensor(1.0375)\n",
            "epoch: 32 loss:tensor(1.0362)\n",
            "epoch: 33 loss:tensor(1.0362)\n",
            "epoch: 34 loss:tensor(1.0359)\n",
            "epoch: 35 loss:tensor(1.0353)\n",
            "epoch: 36 loss:tensor(1.0341)\n",
            "epoch: 37 loss:tensor(1.0343)\n",
            "epoch: 38 loss:tensor(1.0325)\n",
            "epoch: 39 loss:tensor(1.0334)\n",
            "epoch: 40 loss:tensor(1.0322)\n",
            "epoch: 41 loss:tensor(1.0315)\n",
            "epoch: 42 loss:tensor(1.0314)\n",
            "epoch: 43 loss:tensor(1.0304)\n",
            "epoch: 44 loss:tensor(1.0290)\n",
            "epoch: 45 loss:tensor(1.0281)\n",
            "epoch: 46 loss:tensor(1.0279)\n",
            "epoch: 47 loss:tensor(1.0301)\n",
            "epoch: 48 loss:tensor(1.0287)\n",
            "epoch: 49 loss:tensor(1.0279)\n",
            "epoch: 50 loss:tensor(1.0272)\n",
            "epoch: 51 loss:tensor(1.0263)\n",
            "epoch: 52 loss:tensor(1.0252)\n",
            "epoch: 53 loss:tensor(1.0248)\n",
            "epoch: 54 loss:tensor(1.0242)\n",
            "epoch: 55 loss:tensor(1.0221)\n",
            "epoch: 56 loss:tensor(1.0216)\n",
            "epoch: 57 loss:tensor(1.0201)\n",
            "epoch: 58 loss:tensor(1.0181)\n",
            "epoch: 59 loss:tensor(1.0171)\n",
            "epoch: 60 loss:tensor(1.0160)\n",
            "epoch: 61 loss:tensor(1.0143)\n",
            "epoch: 62 loss:tensor(1.0102)\n",
            "epoch: 63 loss:tensor(1.0101)\n",
            "epoch: 64 loss:tensor(1.0095)\n",
            "epoch: 65 loss:tensor(1.0120)\n",
            "epoch: 66 loss:tensor(1.0099)\n",
            "epoch: 67 loss:tensor(1.0066)\n",
            "epoch: 68 loss:tensor(1.0086)\n",
            "epoch: 69 loss:tensor(1.0060)\n",
            "epoch: 70 loss:tensor(1.0028)\n",
            "epoch: 71 loss:tensor(1.0077)\n",
            "epoch: 72 loss:tensor(1.0079)\n",
            "epoch: 73 loss:tensor(1.0068)\n",
            "epoch: 74 loss:tensor(1.0040)\n",
            "epoch: 75 loss:tensor(1.0029)\n",
            "epoch: 76 loss:tensor(1.0010)\n",
            "epoch: 77 loss:tensor(0.9990)\n",
            "epoch: 78 loss:tensor(0.9971)\n",
            "epoch: 79 loss:tensor(0.9974)\n",
            "epoch: 80 loss:tensor(0.9950)\n",
            "epoch: 81 loss:tensor(0.9933)\n",
            "epoch: 82 loss:tensor(0.9931)\n",
            "epoch: 83 loss:tensor(0.9916)\n",
            "epoch: 84 loss:tensor(0.9971)\n",
            "epoch: 85 loss:tensor(0.9960)\n",
            "epoch: 86 loss:tensor(0.9981)\n",
            "epoch: 87 loss:tensor(0.9969)\n",
            "epoch: 88 loss:tensor(0.9967)\n",
            "epoch: 89 loss:tensor(0.9974)\n",
            "epoch: 90 loss:tensor(0.9943)\n",
            "epoch: 91 loss:tensor(0.9938)\n",
            "epoch: 92 loss:tensor(0.9915)\n",
            "epoch: 93 loss:tensor(0.9911)\n",
            "epoch: 94 loss:tensor(0.9897)\n",
            "epoch: 95 loss:tensor(0.9867)\n",
            "epoch: 96 loss:tensor(0.9854)\n",
            "epoch: 97 loss:tensor(0.9840)\n",
            "epoch: 98 loss:tensor(0.9817)\n",
            "epoch: 99 loss:tensor(0.9826)\n",
            "epoch: 100 loss:tensor(0.9841)\n",
            "epoch: 101 loss:tensor(0.9832)\n",
            "epoch: 102 loss:tensor(0.9819)\n",
            "epoch: 103 loss:tensor(0.9806)\n",
            "epoch: 104 loss:tensor(0.9797)\n",
            "epoch: 105 loss:tensor(0.9782)\n",
            "epoch: 106 loss:tensor(0.9759)\n",
            "epoch: 107 loss:tensor(0.9775)\n",
            "epoch: 108 loss:tensor(0.9863)\n",
            "epoch: 109 loss:tensor(0.9853)\n",
            "epoch: 110 loss:tensor(0.9839)\n",
            "epoch: 111 loss:tensor(0.9829)\n",
            "epoch: 112 loss:tensor(0.9833)\n",
            "epoch: 113 loss:tensor(0.9810)\n",
            "epoch: 114 loss:tensor(0.9803)\n",
            "epoch: 115 loss:tensor(0.9787)\n",
            "epoch: 116 loss:tensor(0.9771)\n",
            "epoch: 117 loss:tensor(0.9766)\n",
            "epoch: 118 loss:tensor(0.9747)\n",
            "epoch: 119 loss:tensor(0.9745)\n",
            "epoch: 120 loss:tensor(0.9719)\n",
            "epoch: 121 loss:tensor(0.9719)\n",
            "epoch: 122 loss:tensor(0.9694)\n",
            "epoch: 123 loss:tensor(0.9696)\n",
            "epoch: 124 loss:tensor(0.9674)\n",
            "epoch: 125 loss:tensor(0.9677)\n",
            "epoch: 126 loss:tensor(0.9658)\n",
            "epoch: 127 loss:tensor(0.9661)\n",
            "epoch: 128 loss:tensor(0.9640)\n",
            "epoch: 129 loss:tensor(0.9638)\n",
            "epoch: 130 loss:tensor(0.9635)\n",
            "epoch: 131 loss:tensor(0.9619)\n",
            "epoch: 132 loss:tensor(0.9615)\n",
            "epoch: 133 loss:tensor(0.9613)\n",
            "epoch: 134 loss:tensor(0.9597)\n",
            "epoch: 135 loss:tensor(0.9596)\n",
            "epoch: 136 loss:tensor(0.9593)\n",
            "epoch: 137 loss:tensor(0.9574)\n",
            "epoch: 138 loss:tensor(0.9562)\n",
            "epoch: 139 loss:tensor(0.9575)\n",
            "epoch: 140 loss:tensor(0.9561)\n",
            "epoch: 141 loss:tensor(0.9545)\n",
            "epoch: 142 loss:tensor(0.9538)\n",
            "epoch: 143 loss:tensor(0.9522)\n",
            "epoch: 144 loss:tensor(0.9523)\n",
            "epoch: 145 loss:tensor(0.9529)\n",
            "epoch: 146 loss:tensor(0.9527)\n",
            "epoch: 147 loss:tensor(0.9550)\n",
            "epoch: 148 loss:tensor(0.9532)\n",
            "epoch: 149 loss:tensor(0.9531)\n",
            "epoch: 150 loss:tensor(0.9552)\n",
            "epoch: 151 loss:tensor(0.9552)\n",
            "epoch: 152 loss:tensor(0.9534)\n",
            "epoch: 153 loss:tensor(0.9507)\n",
            "epoch: 154 loss:tensor(0.9498)\n",
            "epoch: 155 loss:tensor(0.9478)\n",
            "epoch: 156 loss:tensor(0.9461)\n",
            "epoch: 157 loss:tensor(0.9442)\n",
            "epoch: 158 loss:tensor(0.9440)\n",
            "epoch: 159 loss:tensor(0.9425)\n",
            "epoch: 160 loss:tensor(0.9402)\n",
            "epoch: 161 loss:tensor(0.9390)\n",
            "epoch: 162 loss:tensor(0.9382)\n",
            "epoch: 163 loss:tensor(0.9376)\n",
            "epoch: 164 loss:tensor(0.9375)\n",
            "epoch: 165 loss:tensor(0.9563)\n",
            "epoch: 166 loss:tensor(0.9561)\n",
            "epoch: 167 loss:tensor(0.9520)\n",
            "epoch: 168 loss:tensor(0.9491)\n",
            "epoch: 169 loss:tensor(0.9474)\n",
            "epoch: 170 loss:tensor(0.9457)\n",
            "epoch: 171 loss:tensor(0.9438)\n",
            "epoch: 172 loss:tensor(0.9431)\n",
            "epoch: 173 loss:tensor(0.9413)\n",
            "epoch: 174 loss:tensor(0.9403)\n",
            "epoch: 175 loss:tensor(0.9388)\n",
            "epoch: 176 loss:tensor(0.9378)\n",
            "epoch: 177 loss:tensor(0.9367)\n",
            "epoch: 178 loss:tensor(0.9362)\n",
            "epoch: 179 loss:tensor(0.9352)\n",
            "epoch: 180 loss:tensor(0.9342)\n",
            "epoch: 181 loss:tensor(0.9342)\n",
            "epoch: 182 loss:tensor(0.9328)\n",
            "epoch: 183 loss:tensor(0.9316)\n",
            "epoch: 184 loss:tensor(0.9310)\n",
            "epoch: 185 loss:tensor(0.9300)\n",
            "epoch: 186 loss:tensor(0.9341)\n",
            "epoch: 187 loss:tensor(0.9380)\n",
            "epoch: 188 loss:tensor(0.9330)\n",
            "epoch: 189 loss:tensor(0.9304)\n",
            "epoch: 190 loss:tensor(0.9294)\n",
            "epoch: 191 loss:tensor(0.9321)\n",
            "epoch: 192 loss:tensor(0.9309)\n",
            "epoch: 193 loss:tensor(0.9293)\n",
            "epoch: 194 loss:tensor(0.9272)\n",
            "epoch: 195 loss:tensor(0.9266)\n",
            "epoch: 196 loss:tensor(0.9272)\n",
            "epoch: 197 loss:tensor(0.9313)\n",
            "epoch: 198 loss:tensor(0.9288)\n",
            "epoch: 199 loss:tensor(0.9261)\n",
            "epoch: 200 loss:tensor(0.9272)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sqGZKddT_WkC",
        "colab_type": "code",
        "outputId": "f215a96c-5247-481a-8c13-8edfe21f0174",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "# testing the model\n",
        "\n",
        "test_loss = 0.\n",
        "s = 0.\n",
        "with torch.no_grad():\n",
        "  for id_user in range(nb_users):\n",
        "    input = Variable(training_set[id_user]).unsqueeze(0)\n",
        "    target = Variable(test_set[id_user]).unsqueeze(0)\n",
        "    if torch.sum(target.data > 0) > 0:\n",
        "      output = sae(input)\n",
        "      output[target == 0] = 0\n",
        "      loss = criterion(output, target)\n",
        "      mean_corrector = nb_movies / float(torch.sum(target.data > 0) + 1e-10)\n",
        "      test_loss += np.sqrt(loss.data[0] * mean_corrector)\n",
        "      s += 1.\n",
        "print('test loss:'+str(test_loss/s))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test loss:tensor(0.9891)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}