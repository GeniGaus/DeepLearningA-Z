{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BoltzmannMachine.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/GeniGaus/100DaysOfMLCode/blob/master/BoltzmannMachine_MovieRecommendation.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "ihnKRLPwddtQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Restricted Boltzmann Machine(RBM)\n",
        "------------------\n",
        "\n",
        "### RBM as Energy-based model\n",
        "\n",
        "RBM can be viewed as energy based model where energy of the system is defined by the weights of the nodes. In order to optimize the RBM, we need to minimize its energy by finding out the gradient.\n",
        "\n",
        "\n",
        "### RBM as graphical model\n",
        "\n",
        "RBM can also be viewed as a probabilistic graphical model where to optimize it, we maximize the log-likelihood of the training set.\n",
        "\n",
        "--------------------\n",
        "\n",
        "In order to minimize energy or maximize the log-likelihood, we compute the gradients. Since the computation of these gradients is very heavy, we use gradient approximation techniques to find the gradient and make small adjustments in the direction of the right gradient.\n",
        "\n",
        "This is slightly similar to the process followed by supervised learning models. There we try to minimize the loss function. For that we compute the gradient of the loss function and updated the weights in the direction of minimum loss.\n",
        "\n",
        "Similarly, for RBM, we compute the gradient and update the weights. Since the direct computation of gradients is too heavy, we approximate these gradients. For that we use Contrastive Divergence.\n",
        "\n",
        "### Contrastive Divergence (CD)\n",
        "\n",
        "**CD** is an algorithm to approximate the gradients. It uses **Gibbs Sampling**. **Gibbs Sampling** consists of creating the *Gibbs chain* in k steps. *Gibbs chain* consist of sampling k times the visible nodes and hidden nodes. For this, we take the input vector $v_0$ and then based on probabilities $p(h|v)$, we sample hidden nodes. Then we take the sampled hidden nodes vector as input and using $p(v|h)$, we sample the input vector $v_1$.\n",
        "\n",
        "We reapeat this process **k times** and this is called as **$CD_k$**.\n",
        "\n",
        "![k-step CD Algo](https://raw.githubusercontent.com/GeniGaus/100DaysOfMLCode/master/assets/CDk.png)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "ChpFdy0Oi81Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "1f39295b-771e-4281-c4ff-8689d1db9365"
      },
      "cell_type": "code",
      "source": [
        "# Install a Drive FUSE wrapper.\n",
        "# https://github.com/astrada/google-drive-ocamlfuse\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package libfuse2:amd64.\n",
            "(Reading database ... 22278 files and directories currently installed.)\n",
            "Preparing to unpack .../libfuse2_2.9.7-1ubuntu1_amd64.deb ...\n",
            "Unpacking libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
            "Selecting previously unselected package fuse.\n",
            "Preparing to unpack .../fuse_2.9.7-1ubuntu1_amd64.deb ...\n",
            "Unpacking fuse (2.9.7-1ubuntu1) ...\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.0-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.0-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Setting up fuse (2.9.7-1ubuntu1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.0-0ubuntu1~ubuntu18.04.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lFd4sVcfi9w3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Generate auth tokens for Colab\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K6IHSxmMi9_G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "b7b31071-b265-4a29-d660-0e8d5a9ecd2c"
      },
      "cell_type": "code",
      "source": [
        "# Generate creds for the Drive FUSE library.\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lWRm9ZVyjC6G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create a directory and mount Google Drive using that directory.\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KHq9J_Uogoo_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "04d48248-9d36-4738-983c-e83d0ad3e541"
      },
      "cell_type": "code",
      "source": [
        "## Install Pytorch\n",
        "\n",
        "# http://pytorch.org/\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1073750016 bytes == 0x5c05a000 @  0x7fb87601c2a4 0x594e17 0x626104 0x51190a 0x4f5277 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x4f3338 0x510fb0 0x5119bd 0x4f6070\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D2W3NK0utGys",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('drive/BoltzmannMachine')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D_aRA1P6iWt3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "5d7d5032-2dcf-4469-e085-a34f3dcfaa99"
      },
      "cell_type": "code",
      "source": [
        "!ls -l"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 447\n",
            "-rw-r--r-- 1 root root 448626 Oct 15 09:16 AItRBM-proof.pdf\n",
            "drwxr-xr-x 2 root root   4096 Oct  7 13:16 ml-100k\n",
            "drwxr-xr-x 2 root root   4096 Oct  7 13:16 ml-1m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "r7mud9eUrA6J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Building the model using Pytorch\n",
        "\n",
        "------------------\n"
      ]
    },
    {
      "metadata": {
        "id": "MbOKNgKjq_rI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BAqCGaSxtQyC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# importing dataset\n",
        "movies = pd.read_csv('ml-1m/movies.dat', sep='::', engine='python', encoding='latin-1')\n",
        "users = pd.read_csv('ml-1m/users.dat', sep='::', engine='python', encoding='latin-1')\n",
        "ratings = pd.read_csv('ml-1m/ratings.dat', sep='::', engine='python', encoding='latin-1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "keN9TIrHtzT3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# forming training and test set\n",
        "training_set = pd.read_csv('ml-100k/u1.base', delimiter='\\t')\n",
        "training_set = np.array(training_set, dtype='int')\n",
        "test_set = pd.read_csv('ml-100k/u1.test', delimiter='\\t')\n",
        "test_set = np.array(test_set, dtype='int')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7nB_kk91vg0c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# total no. of users and movies\n",
        "nb_users = max(max(training_set[:, 0]), max(test_set[:, 0]))\n",
        "nb_movies = max(max(training_set[:, 1]), max(test_set[:, 1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "btyi4Bs-wOZQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create training and test matrices where each line is user, each column is movie and each cell contains the rating which that user gave for the movie.\n",
        "# If the user gave no rating, then 0 is placed in that cell.\n",
        "# This will create the input structure which the Boltzmann machine expects,i.e. observations in lines and features in columns.\n",
        "\n",
        "'''rating_matrix = np.zeros((nb_users, nb_movies), dtype='int')\n",
        "full_set = np.concatenate((training_set, test_set), axis=0)\n",
        "for i in range(len(full_set)):\n",
        "  rating_matrix[full_set[i][0]][full_set[i][1]] = full_set[i][2]\n",
        "'''\n",
        "\n",
        "def convert(data):\n",
        "  converted_data = []\n",
        "  for user_id in range(nb_users + 1):\n",
        "    movies_ids = data[:, 1][data[:, 0] == user_id]\n",
        "    ratings_data = data[:, 2][data[:, 0] == user_id]\n",
        "    ratings = np.zeros((nb_movies))\n",
        "    ratings[movies_ids - 1] = ratings_data\n",
        "    converted_data.append(ratings)\n",
        "  \n",
        "  return converted_data\n",
        " \n",
        "training_set = convert(training_set)\n",
        "test_set = convert(test_set)\n",
        "\n",
        "training_set = torch.FloatTensor(training_set)\n",
        "test_set = torch.FloatTensor(test_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U8g1RB6rzOKF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Converting ratings into binary ratings 0(not liked) or 1(liked). \n",
        "\n",
        "training_set[training_set == 0] = -1\n",
        "training_set[training_set == 1] = 0\n",
        "training_set[training_set == 2] = 0\n",
        "training_set[training_set >= 3] = 1\n",
        "\n",
        "test_set[test_set == 0] = -1\n",
        "test_set[test_set == 1] = 0\n",
        "test_set[test_set == 2] = 0\n",
        "test_set[test_set >= 3] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DwPQ0MeIQeJT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### RBM\n",
        "-----------\n",
        "\n",
        "Create RBM from scratch"
      ]
    },
    {
      "metadata": {
        "id": "r4zHCNMbQk62",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class RBM():\n",
        "  \n",
        "  def __init__(self, nv, nh):\n",
        "    self.W = torch.randn((nh, nv))\n",
        "    self.bh = torch.randn((1, nh))\n",
        "    self.bv = torch.randn((1, nv))\n",
        "  \n",
        "  def sample_h(self, x):\n",
        "    wx = torch.mm(x, self.W.t())\n",
        "    activation = wx + self.bh.expand_as(wx)\n",
        "    p_h_given_v = torch.sigmoid(activation)\n",
        "    return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
        "  \n",
        "  def sample_v(self, y):\n",
        "    wy = torch.mm(y, self.W)\n",
        "    activation = wy + self.bv.expand_as(wy)\n",
        "    p_v_given_h = torch.sigmoid(activation)\n",
        "    return p_v_given_h, torch.bernoulli(p_v_given_h)\n",
        "  \n",
        "  def train(self, v0, vk, ph0, phk):\n",
        "    self.W += torch.mm(ph0, v0) - torch.mm(phk, vk)\n",
        "    self.bv += torch.sum(v0 - vk, 0)\n",
        "    self.bh += torch.sum(ph0 - phk, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3AftAYBH5OFl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nb_epochs = 10\n",
        "batch_size = 100\n",
        "k_steps = 10\n",
        "\n",
        "nv = len(training_set[0])\n",
        "nh = 100\n",
        "rbm = RBM(nv, nh)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fqZqrSSt9HdK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "3dd617da-61f5-4c5c-8a2e-4f7fc966e631"
      },
      "cell_type": "code",
      "source": [
        "# training the RBM model\n",
        "for epoch in range(1, nb_epochs + 1):\n",
        "  training_loss = 0\n",
        "  counter = 0.  # for normalization of loss\n",
        "  for id_user in range(0, nb_users - batch_size, batch_size):\n",
        "    v0 = training_set[id_user:id_user+batch_size]\n",
        "    vk = training_set[id_user:id_user+batch_size]\n",
        "    ph0,_ = rbm.sample_h(v0)\n",
        "    for k in range(k_steps):\n",
        "      _,hk = rbm.sample_h(vk)\n",
        "      _,vk = rbm.sample_v(hk)\n",
        "      vk[v0<0] = v0[v0<0]\n",
        "    phk,_ = rbm.sample_h(vk)\n",
        "    rbm.train(v0,vk,ph0,phk)\n",
        "    training_loss += torch.mean(torch.abs(v0[v0>=0] - vk[v0>=0]))\n",
        "    counter += 1.\n",
        "  print('epoch: '+str(epoch)+' loss: '+str(training_loss/counter))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1 loss: tensor(0.3129)\n",
            "epoch: 2 loss: tensor(0.2519)\n",
            "epoch: 3 loss: tensor(0.2550)\n",
            "epoch: 4 loss: tensor(0.2491)\n",
            "epoch: 5 loss: tensor(0.2525)\n",
            "epoch: 6 loss: tensor(0.2517)\n",
            "epoch: 7 loss: tensor(0.2452)\n",
            "epoch: 8 loss: tensor(0.2447)\n",
            "epoch: 9 loss: tensor(0.2417)\n",
            "epoch: 10 loss: tensor(0.2496)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9tsPI05Zj1Nd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ce4acffd-5ea4-4144-e38b-ae4e5fc2fa55"
      },
      "cell_type": "code",
      "source": [
        "# testing the RBM model\n",
        "test_loss = 0\n",
        "counter = 0.\n",
        "for id_user in range(nb_users):\n",
        "  v = training_set[id_user:id_user+1]\n",
        "  vt = test_set[id_user:id_user+1]\n",
        "  if len(v[vt >= 0]) > 0:\n",
        "    _,h = rbm.sample_h(v)\n",
        "    _,v = rbm.sample_v(h)\n",
        "    test_loss += torch.mean(torch.abs(vt[vt>=0] - v[vt>=0]))\n",
        "    counter += 1\n",
        "print('test loss: '+str(test_loss/counter))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test loss: tensor(0.2290)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
